<p align="center">
    <br>
    <img src="https://modelscope.oss-cn-beijing.aliyuncs.com/modelscope.gif" width="400"/>
    <br>
    <h1>FaceChain</h1>
<p>

# æœ€æ–°æ¶ˆæ¯

FaceChainä¸¤é¡¹ç®—æ³•åˆ›æ–°å·¥ä½œ[FaceChain-ImagineID](https://arxiv.org/abs/2403.01901)ä¸FaceChain-SuDeè¢«CVPR 2024æ¥æ”¶å½•ç”¨! (2024-02-27)

# ä»‹ç»

FaceChainæ˜¯ä¸€ä¸ªå¯ä»¥ç”¨æ¥æ‰“é€ ä¸ªäººæ•°å­—å½¢è±¡çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å·¥å…·ã€‚ç”¨æˆ·ä»…éœ€è¦æä¾›æœ€ä½ä¸€å¼ ç…§ç‰‡å³å¯è·å¾—ç‹¬å±äºè‡ªå·±çš„ä¸ªäººå½¢è±¡æ•°å­—æ›¿èº«ã€‚FaceChainæ”¯æŒåœ¨gradioçš„ç•Œé¢ä¸­ä½¿ç”¨æ¨¡å‹è®­ç»ƒå’Œæ¨ç†èƒ½åŠ›ã€æ”¯æŒèµ„æ·±å¼€å‘è€…ä½¿ç”¨pythonè„šæœ¬è¿›è¡Œè®­ç»ƒæ¨ç†ï¼Œä¹Ÿæ”¯æŒåœ¨sd webuiä¸­å®‰è£…æ’ä»¶ä½¿ç”¨ï¼›åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿæ¬¢è¿å¼€å‘è€…å¯¹æœ¬Repoè¿›è¡Œç»§ç»­å¼€å‘å’Œè´¡çŒ®ã€‚
FaceChainçš„æ¨¡å‹ç”±[ModelScope](https://github.com/modelscope/modelscope)å¼€æºæ¨¡å‹ç¤¾åŒºæä¾›æ”¯æŒã€‚

<p align="center">
        ModelScope Studio <a href="https://modelscope.cn/studios/CVstudio/cv_human_portrait/summary">ğŸ¤–<a></a>&nbsp ï½œAPI <a href="https://help.aliyun.com/zh/dashscope/developer-reference/facechain-quick-start">ğŸ”¥<a></a>&nbsp ï½œ API's Example App <a href="https://tongyi.aliyun.com/wanxiang/app/portrait-gallery">ğŸ”¥<a></a>&nbsp | SD WebUI ï½œ HuggingFace Space <a href="https://huggingface.co/spaces/modelscope/FaceChain">ğŸ¤—</a>&nbsp 
</p>
<br>

![image](resources/git_cover_CH.jpg)



# News
- FaceChainä¸¤é¡¹ç®—æ³•åˆ›æ–°å·¥ä½œ[FaceChain-ImagineID](https://arxiv.org/abs/2403.01901)ä¸FaceChain-SuDeè¢«CVPR 2024æ¥æ”¶å½•ç”¨! (2024-02-27)
- ğŸ†ğŸ†ğŸ†é˜¿é‡Œå·´å·´å¹´åº¦å¼€æºæ–°é”é¡¹ç›®ã€é˜¿é‡Œå·´å·´å¹´åº¦å¼€æºå…ˆé”‹äººç‰©-æŠ€æœ¯è´¡çŒ®ï¼ˆåˆ˜æ´‹ï¼‰ã€é˜¿é‡Œå·´å·´å¹´åº¦å¼€æºå…ˆé”‹äººç‰©-ç”Ÿæ€è´¡çŒ®ï¼ˆå­™ä½°è´µï¼‰. (2024-01-20)
- ä¸NUSå›¢é˜Ÿåˆä½œçš„[InfoBatch](https://github.com/henryqin1997/InfoBatch) è¢«ICLR 2024(Oral)å½•ç”¨! pytorchä¸­åªç”¨3è¡Œä»£ç çš„ç‰ˆæœ¬PRä¸­. (2024-01-16)
- ğŸ†å¼€æ”¾åŸå­2023å¿«é€Ÿæˆé•¿å¼€æºé¡¹ç›®å¥–é¡¹. (2023-12-20)
- æ”¯æŒSDXLæ¨¡å—ğŸ”¥ğŸ”¥ğŸ”¥ï¼Œå‡ºå›¾ç»†è…»åº¦å¤§å¹…æå‡. (November 22th, 2023 UTC)
- æ”¯æŒè¶…åˆ†æ¨¡å—ğŸ”¥ğŸ”¥ğŸ”¥ï¼Œç›®å‰å¤šç§åˆ†è¾¨ç‡å¯é€‰ (512*512, 768*768, 1024*1024, 2048*2048). (November 13th, 2023 UTC)
- ğŸ†FaceChainå…¥é€‰[BenchCouncil Open100 (2022-2023)](https://www.benchcouncil.org/evaluation/opencs/annual.html#Institutions) å¼€æºæ¦œå•. (2023-11-08)
- å¢åŠ è™šæ‹Ÿè¯•è¡£æ¨¡å—ï¼Œå¯åŸºäºåŒ…å«ç»™å®šæœé¥°çš„æ¨¡ç‰¹å›¾æˆ–äººå°å›¾è¿›è¡Œé‡ç»˜. (2023-10-27)
- å¢åŠ ä¸‡ç›¸ç‰ˆæœ¬[åœ¨çº¿å…è´¹åº”ç”¨](https://tongyi.aliyun.com/wanxiang/app/portrait-gallery). (2023-10-26)
- ğŸ†1024ç¨‹åºå‘˜èŠ‚AIGCåº”ç”¨å·¥å…·æœ€å…·å•†ä¸šä»·å€¼å¥–. (2023-10-24)
- stable-diffusion-webuiæ”¯æŒğŸ”¥ğŸ”¥ğŸ”¥. (2023-10-13)
- é«˜æ€§èƒ½çš„(å•äºº&åŒäºº)æ¨¡ç‰ˆé‡ç»˜åŠŸèƒ½ï¼Œç®€åŒ–ç”¨æˆ·ç•Œé¢. (2023-09-09)
- æ›´å¤šæŠ€æœ¯ç»†èŠ‚å¯ä»¥åœ¨ [è®ºæ–‡](https://arxiv.org/abs/2308.14256) é‡ŒæŸ¥çœ‹. (2023-08-30)
- ä¸ºLoraè®­ç»ƒæ·»åŠ éªŒè¯å’Œæ ¹æ®face_idçš„èåˆï¼Œå¹¶æ·»åŠ InpaintTabï¼ˆç›®å‰åœ¨Gradioç•Œé¢ä¸Šæš‚æ—¶é»˜è®¤éšè—ï¼‰. (2023-08-28)
- å¢åŠ å§¿åŠ¿æ§åˆ¶æ¨¡å—ï¼Œå¯ä¸€é”®ä½“éªŒæ¨¡ç‰ˆposeå¤åˆ». (2023-08-27)
- å¢åŠ é²æ£’æ€§äººè„¸loraè®­ç»ƒï¼Œæå‡å•å›¾è®­ç»ƒ&é£æ ¼loraèåˆçš„æ•ˆæœ. (2023-08-27)
- æ”¯æŒåœ¨HuggingFace Spaceä¸­ä½“éªŒFaceChain ï¼ <a href="https://huggingface.co/spaces/modelscope/FaceChain">ğŸ¤—</a>      (2023-08-25)
- æ–°å¢é«˜è´¨é‡æç¤ºè¯æ¨¡æ¿ï¼Œæ¬¢è¿å¤§å®¶ä¸€èµ·è´¡çŒ®ï¼ å‚è€ƒ [awesome-prompts-facechain](resources/awesome-prompts-facechain.txt)    (2023-08-18)
- æ”¯æŒå³æ’å³ç”¨çš„é£æ ¼LoRAæ¨¡å‹ï¼ (2023-08-16)
- æ–°å¢ä¸ªæ€§åŒ–promptæ¨¡å—ï¼ (2023-08-16)
- Colab notebookå®‰è£…å·²æ”¯æŒï¼Œæ‚¨å¯ä»¥ç›´æ¥æ‰“å¼€é“¾æ¥ä½“éªŒFaceChainï¼š [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/modelscope/facechain/blob/main/facechain_demo.ipynb)   (2023-08-15)


# å¾…åŠäº‹é¡¹
- ç ”å‘å…è®­ç»ƒæ¨¡å—ï¼Œè¾¾æˆCPUè¿è¡Œçš„ç›®æ ‡
- ç ”å‘RLHFæ¨¡å—ï¼Œè¿›ä¸€æ­¥æå‡ä¸Šé™
- å¢åŠ é£æ ¼loraçš„è®­ç»ƒæ¥å£
- ç°æˆé£æ ¼æ¨¡å‹å³æ’å³ç”¨ï¼ˆä»¥Cç«™é£æ ¼æ¨¡å‹ä¸ºä¾‹ï¼‰
- å¢åŠ æ›´å¤šç¾è‚¤åŠŸèƒ½
- å¼€å‘æ›´å¤šå¥½ç©çš„app


# Citation

å¦‚æœFaceChainå¯¹æ‚¨çš„ç ”ç©¶æœ‰æ‰€å¸®åŠ©ï¼Œè¯·åœ¨æ‚¨çš„å‡ºç‰ˆç‰©ä¸­å¼•ç”¨FaceChain
```
@article{liu2023facechain,
  title={FaceChain: A Playground for Identity-Preserving Portrait Generation},
  author={Liu, Yang and Yu, Cheng and Shang, Lei and Wu, Ziheng and 
          Wang, Xingjun and Zhao, Yuze and Zhu, Lin and Cheng, Chen and 
          Chen, Weitao and Xu, Chao and Xie, Haoyu and Yao, Yuan and 
          Zhou,  Wenmeng and Chen Yingda and Xie, Xuansong and Sun, Baigui},
  journal={arXiv preprint arXiv:2308.14256},
  year={2023}
```

# ç¯å¢ƒå‡†å¤‡

## å…¼å®¹æ€§éªŒè¯
FaceChainæ˜¯ä¸€ä¸ªç»„åˆæ¨¡å‹ï¼ŒåŸºäºPyTorchæœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œä»¥ä¸‹æ˜¯å·²ç»éªŒè¯è¿‡çš„ä¸»è¦ç¯å¢ƒä¾èµ–ï¼š
- pythonç¯å¢ƒ: py3.8, py3.10
- pytorchç‰ˆæœ¬: torch2.0.0, torch2.0.1
- CUDAç‰ˆæœ¬: 11.7
- CUDNNç‰ˆæœ¬: 8+
- æ“ä½œç³»ç»Ÿç‰ˆæœ¬: Ubuntu 20.04, CentOS 7.9
- GPUå‹å·: Nvidia-A10 24G


## èµ„æºè¦æ±‚
- GPU: æ˜¾å­˜å ç”¨çº¦19G
- ç£ç›˜: æ¨èé¢„ç•™50GBä»¥ä¸Šçš„å­˜å‚¨ç©ºé—´


## å®‰è£…æŒ‡å—
æ”¯æŒä»¥ä¸‹å‡ ç§å®‰è£…æ–¹å¼ï¼Œä»»é€‰å…¶ä¸€ï¼š

### 1. ä½¿ç”¨ModelScopeæä¾›çš„notebookç¯å¢ƒã€æ¨èã€‘
ModelScope(é­”æ­ç¤¾åŒº)æä¾›ç»™æ–°ç”¨æˆ·åˆå§‹çš„å…è´¹è®¡ç®—èµ„æºï¼Œå‚è€ƒ[ModelScope Notebook](https://modelscope.cn/my/mynotebook/preset)
    
å¦‚æœåˆå§‹å…è´¹è®¡ç®—èµ„æºæ— æ³•æ»¡è¶³è¦æ±‚ï¼Œæ‚¨è¿˜å¯ä»¥ä»ä¸Šè¿°é¡µé¢å¼€é€šä»˜è´¹æµç¨‹ï¼Œä»¥ä¾¿åˆ›å»ºä¸€ä¸ªå‡†å¤‡å°±ç»ªçš„ModelScope(GPU) DSWé•œåƒå®ä¾‹ã€‚
    
Notebookç¯å¢ƒä½¿ç”¨ç®€å•ï¼Œæ‚¨åªéœ€è¦æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼ˆæ³¨æ„ï¼šç›®å‰æš‚ä¸æä¾›æ°¸ä¹…å­˜å‚¨ï¼Œå®ä¾‹é‡å¯åæ•°æ®ä¼šä¸¢å¤±ï¼‰ï¼š


```shell
# Step1: æˆ‘çš„notebook -> PAI-DSW -> GPUç¯å¢ƒ

# Step2: è¿›å…¥Notebook cellï¼Œæ‰§è¡Œä¸‹è¿°å‘½ä»¤ä»github cloneä»£ç ï¼š
!GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1

# Step3: åˆ‡æ¢å½“å‰å·¥ä½œè·¯å¾„ï¼Œå®‰è£…ä¾èµ–
import os
os.chdir('/mnt/workspace/facechain')    # æ³¨æ„æ›¿æ¢æˆä¸Šè¿°cloneåçš„ä»£ç æ–‡ä»¶å¤¹ä¸»è·¯å¾„
print(os.getcwd())

!pip3 install gradio==3.50.2
!pip3 install controlnet_aux==0.0.6
!pip3 install python-slugify
!pip3 install onnxruntime==1.15.1
!pip3 install edge-tts
!pip3 install modelscope==1.10.0

# Step4: å¯åŠ¨æœåŠ¡ï¼Œç‚¹å‡»ç”Ÿæˆçš„URLå³å¯è®¿é—®webé¡µé¢ï¼Œä¸Šä¼ ç…§ç‰‡å¼€å§‹è®­ç»ƒå’Œé¢„æµ‹
!python3 app.py

```

é™¤äº†ModelScopeå…¥å£ä»¥å¤–ï¼Œæ‚¨ä¹Ÿå¯ä»¥å‰å¾€[PAI-DSW](https://www.aliyun.com/activity/bigdata/pai/dsw) ç›´æ¥è´­ä¹°å¸¦æœ‰ModelScopeé•œåƒçš„è®¡ç®—å®ä¾‹ï¼ˆæ¨èä½¿ç”¨A10èµ„æºï¼‰ï¼Œè¿™æ ·åŒæ ·å¯ä»¥ä½¿ç”¨å¦‚ä¸Šçš„æœ€ç®€æ­¥éª¤è¿è¡Œèµ·æ¥ã€‚



### 2. dockeré•œåƒ

å¦‚æœæ‚¨ç†Ÿæ‚‰dockerï¼Œå¯ä»¥ä½¿ç”¨æˆ‘ä»¬æä¾›çš„dockeré•œåƒï¼Œå…¶åŒ…å«äº†æ¨¡å‹ä¾èµ–çš„æ‰€æœ‰ç»„ä»¶ï¼Œæ— éœ€å¤æ‚çš„ç¯å¢ƒå®‰è£…ï¼š
```shell
# Step1: æœºå™¨èµ„æº
æ‚¨å¯ä»¥ä½¿ç”¨æœ¬åœ°æˆ–äº‘ç«¯å¸¦æœ‰GPUèµ„æºçš„è¿è¡Œç¯å¢ƒã€‚
å¦‚éœ€ä½¿ç”¨é˜¿é‡Œäº‘ECSï¼Œå¯è®¿é—®ï¼š https://www.aliyun.com/product/ecsï¼Œæ¨èä½¿ç”¨â€é•œåƒå¸‚åœºâ€œä¸­çš„CentOS 7.9 64ä½(é¢„è£…NVIDIA GPUé©±åŠ¨)

# Step2: å°†é•œåƒä¸‹è½½åˆ°æœ¬åœ° ï¼ˆå‰ææ˜¯å·²ç»å®‰è£…äº†docker engineå¹¶å¯åŠ¨æœåŠ¡ï¼Œå…·ä½“å¯å‚è€ƒï¼š https://docs.docker.com/engine/install/ï¼‰
# For China Mainland users:
docker pull registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.8.0-py38-torch2.0.1-tf2.13.0-1.9.4
# For users outside China Mainland:
docker pull registry.us-west-1.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.8.0-py38-torch2.0.1-tf2.13.0-1.9.4

# Step3: æ‹‰èµ·é•œåƒè¿è¡Œ
docker run -it --name facechain -p 7860:7860 --gpus all registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.8.0-py38-torch2.0.1-tf2.13.0-1.9.4 /bin/bash  # æ³¨æ„ your_xxx_image_id æ›¿æ¢æˆä½ çš„é•œåƒid
# æ³¨æ„ï¼š å¦‚æœæç¤ºæ— æ³•ä½¿ç”¨å®¿ä¸»æœºGPUçš„é”™è¯¯ï¼Œå¯èƒ½éœ€è¦å®‰è£…nvidia-container-runtime
# 1. å®‰è£…nvidia-container-runtimeï¼šhttps://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
# 2. é‡å¯dockeræœåŠ¡ï¼šsudo systemctl restart docker

# Step4: åœ¨å®¹å™¨ä¸­å®‰è£…gradio
pip3 install gradio==3.50.2
pip3 install controlnet_aux==0.0.6
pip3 install python-slugify
pip3 install onnxruntime==1.15.1
pip3 install edge-tts
pip3 install modelscope==1.10.0

# Step5: è·å–facechainæºä»£ç 
GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1
cd facechain
python3 app.py
# Note: FaceChainç›®å‰æ”¯æŒå•å¡GPUï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒæœ‰å¤šå¡ï¼Œè¯·ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤
# CUDA_VISIBLE_DEVICES=0 python3 app.py

# Step6: ç‚¹å‡» "public URL", å½¢å¼ä¸º https://xxx.gradio.live
```


### 3. condaè™šæ‹Ÿç¯å¢ƒ

ä½¿ç”¨condaè™šæ‹Ÿç¯å¢ƒï¼Œå‚è€ƒ[Anaconda](https://docs.anaconda.com/anaconda/install/)æ¥ç®¡ç†æ‚¨çš„ä¾èµ–ï¼Œå®‰è£…å®Œæˆåï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š
(æç¤ºï¼š mmcvå¯¹ç¯å¢ƒè¦æ±‚è¾ƒé«˜ï¼Œå¯èƒ½å‡ºç°ä¸é€‚é…çš„æƒ…å†µï¼Œæ¨èä½¿ç”¨dockeræ–¹å¼)

```shell
conda create -n facechain python=3.8    # å·²éªŒè¯ç¯å¢ƒï¼š3.8 å’Œ 3.10
conda activate facechain

GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1
cd facechain

pip3 install -r requirements.txt
pip3 install -U openmim 
mim install mmcv-full==1.7.0

# è¿›å…¥facechainæ–‡ä»¶å¤¹ï¼Œæ‰§è¡Œï¼š
python3 app.py
# Note: FaceChainç›®å‰æ”¯æŒå•å¡GPUï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒæœ‰å¤šå¡ï¼Œè¯·ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤
# CUDA_VISIBLE_DEVICES=0 python3 app.py

# æœ€åç‚¹å‡»logä¸­ç”Ÿæˆçš„URLå³å¯è®¿é—®é¡µé¢ã€‚
```

å¤‡æ³¨ï¼šå¦‚æœæ˜¯Windowsç¯å¢ƒè¿˜éœ€è¦æ³¨æ„ä»¥ä¸‹æ­¥éª¤ï¼š
```shell
# pipæ–¹å¼å®‰è£…mmcv-full: pip3 install mmcv-full
```

**å¦‚æœæ‚¨æƒ³è¦ä½¿ç”¨"äººç‰©è¯´è¯è§†é¢‘ç”Ÿæˆ"æ ‡ç­¾é¡µçš„åŠŸèƒ½ï¼Œè¯·å‚è€ƒ[installation_for_talkinghead_ZH](doc/installation_for_talkinghead_ZH.md)é‡Œçš„å®‰è£…ä½¿ç”¨æ•™ç¨‹ã€‚**


### 4. colabè¿è¡Œ

| Colab | Info
| --- | --- |
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/modelscope/facechain/blob/main/facechain_demo.ipynb) | FaceChain Installation on Colab


### 5. stable-diffusion-webuiä¸­è¿è¡Œ
1. é€‰æ‹©`Extensions Tab`ï¼Œ é€‰æ‹©`Install From URL`(å®˜æ–¹æ’ä»¶é›†æˆä¸­ï¼Œå…ˆä»URLå®‰è£…)
![image](resources/sdwebui_install.png)

2. åˆ‡æ¢åˆ°`Installed`ï¼Œå‹¾é€‰FaceChainæ’ä»¶ï¼Œç‚¹å‡»`Apply and restart UI`
![image](resources/sdwebui_restart.png)

3. é¡µé¢åˆ·æ–°åï¼Œå‡ºç°`FaceChain` Tabè¯´æ˜å®‰è£…æˆåŠŸ
![image](resources/sdwebui_success.png)




å¤‡æ³¨ï¼šappæœåŠ¡æˆåŠŸå¯åŠ¨åï¼Œåœ¨logä¸­è®¿é—®é¡µé¢URLï¼Œè¿›å…¥â€å½¢è±¡å®šåˆ¶â€œtabé¡µï¼Œç‚¹å‡»â€œé€‰æ‹©å›¾ç‰‡ä¸Šä¼ â€ï¼Œå¹¶æœ€å°‘é€‰1å¼ åŒ…å«äººè„¸çš„å›¾ç‰‡ï¼›ç‚¹å‡»â€œå¼€å§‹è®­ç»ƒâ€å³å¯è®­ç»ƒæ¨¡å‹ã€‚è®­ç»ƒå®Œæˆåæ—¥å¿—ä¸­ä¼šæœ‰å¯¹åº”å±•ç¤ºï¼Œä¹‹ååˆ‡æ¢åˆ°â€œå½¢è±¡ä½“éªŒâ€æ ‡ç­¾é¡µç‚¹å‡»â€œå¼€å§‹ç”Ÿæˆâ€å³å¯ç”Ÿæˆå±äºè‡ªå·±çš„æ•°å­—å½¢è±¡ã€‚

# è„šæœ¬è¿è¡Œ

å¦‚æœä¸æƒ³å¯åŠ¨æœåŠ¡ï¼Œè€Œæ˜¯ç›´æ¥åœ¨å‘½ä»¤è¡Œè¿›è¡Œå¼€å‘è°ƒè¯•ç­‰å·¥ä½œï¼ŒFaceChainä¹Ÿæ”¯æŒåœ¨pythonç¯å¢ƒä¸­ç›´æ¥è¿è¡Œè„šæœ¬è¿›è¡Œè®­ç»ƒå’Œæ¨ç†ã€‚åœ¨å…‹éš†åçš„æ–‡ä»¶å¤¹ä¸­ç›´æ¥è¿è¡Œå¦‚ä¸‹å‘½ä»¤æ¥è¿›è¡Œè®­ç»ƒï¼š

```shell
PYTHONPATH=. sh train_lora.sh "ly261666/cv_portrait_model" "v2.0" "film/film" "./data/cache_imei/a_spec_imei/input_img" "./data/cache_imei/a_spec_imei/output_processed" "./data/cache_imei/a_spec_imei/output_train"
```

å‚æ•°å«ä¹‰ï¼š

```text
ly261666/cv_portrait_model: ModelScopeæ¨¡å‹ä»“åº“çš„stable diffusionåŸºæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¼šç”¨äºè®­ç»ƒï¼Œå¯ä»¥ä¸ä¿®æ”¹
v2.0: è¯¥åŸºæ¨¡å‹çš„ç‰ˆæœ¬å·ï¼Œå¯ä»¥ä¸ä¿®æ”¹
film/film: è¯¥åŸºæ¨¡å‹åŒ…å«äº†å¤šä¸ªä¸åŒé£æ ¼çš„å­ç›®å½•ï¼Œå…¶ä¸­ä½¿ç”¨äº†film/filmç›®å½•ä¸­çš„é£æ ¼æ¨¡å‹ï¼Œå¯ä»¥ä¸ä¿®æ”¹
./data/cache_imei/a_spec_imei/input_img: æœ¬å‚æ•°éœ€è¦ç”¨å®é™…å€¼æ›¿æ¢ï¼Œæœ¬å‚æ•°æ˜¯ä¸€ä¸ªæœ¬åœ°æ–‡ä»¶ç›®å½•ï¼ŒåŒ…å«äº†ç”¨æ¥è®­ç»ƒå’Œç”Ÿæˆçš„åŸå§‹ç…§ç‰‡
./data/cache_imei/a_spec_imei/output_processed: é¢„å¤„ç†ä¹‹åçš„å›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œè¿™ä¸ªå‚æ•°éœ€è¦åœ¨æ¨ç†ä¸­è¢«ä¼ å…¥ç›¸åŒçš„å€¼ï¼Œå¯ä»¥ä¸ä¿®æ”¹
./data/cache_imei/a_spec_imei/output_train: è®­ç»ƒç”Ÿæˆä¿å­˜æ¨¡å‹weightsçš„æ–‡ä»¶å¤¹ï¼Œå¯ä»¥ä¸ä¿®æ”¹
```

ç­‰å¾…5-20åˆ†é’Ÿå³å¯è®­ç»ƒå®Œæˆã€‚ç”¨æˆ·ä¹Ÿå¯ä»¥è°ƒèŠ‚å…¶ä»–è®­ç»ƒè¶…å‚æ•°ï¼Œè®­ç»ƒæ”¯æŒçš„è¶…å‚æ•°å¯ä»¥æŸ¥çœ‹`train_lora.sh`çš„é…ç½®ï¼Œæˆ–è€…`facechain/train_text_to_image_lora.py`ä¸­çš„å®Œæ•´è¶…å‚æ•°åˆ—è¡¨ã€‚

è¿›è¡Œæ¨ç†æ—¶ï¼Œè¯·ç¼–è¾‘run_inference.pyä¸­çš„ä»£ç :

```python
# ä½¿ç”¨æ·±åº¦æ§åˆ¶ï¼Œé»˜è®¤Falseï¼Œä»…åœ¨ä½¿ç”¨å§¿æ€æ§åˆ¶æ—¶ç”Ÿæ•ˆ
use_depth_control = False
# ä½¿ç”¨å§¿æ€æ§åˆ¶ï¼Œé»˜è®¤False
use_pose_model = False
# å§¿æ€æ§åˆ¶å›¾ç‰‡è·¯å¾„ï¼Œä»…åœ¨ä½¿ç”¨å§¿æ€æ§åˆ¶æ—¶ç”Ÿæ•ˆ
pose_image = 'poses/man/pose1.png'
# å¡«å…¥ä¸Šè¿°çš„é¢„å¤„ç†ä¹‹åçš„å›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œéœ€è¦å’Œè®­ç»ƒæ—¶ç›¸åŒ
processed_dir = './data/cache_imei/a_spec_imei/output_processed'
# æ¨ç†ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡
num_generate = 5
# è®­ç»ƒæ—¶ä½¿ç”¨çš„stable diffusionåŸºæ¨¡å‹ï¼Œå¯ä»¥ä¸ä¿®æ”¹
base_model = 'ly261666/cv_portrait_model'
# è¯¥åŸºæ¨¡å‹çš„ç‰ˆæœ¬å·ï¼Œå¯ä»¥ä¸ä¿®æ”¹
revision = 'v2.0'
# è¯¥åŸºæ¨¡å‹åŒ…å«äº†å¤šä¸ªä¸åŒé£æ ¼çš„å­ç›®å½•ï¼Œå…¶ä¸­ä½¿ç”¨äº†film/filmç›®å½•ä¸­çš„é£æ ¼æ¨¡å‹ï¼Œå¯ä»¥ä¸ä¿®æ”¹
base_model_sub_dir = 'film/film'
# è®­ç»ƒç”Ÿæˆä¿å­˜æ¨¡å‹weightsçš„æ–‡ä»¶å¤¹ï¼Œéœ€è¦ä¿è¯å’Œè®­ç»ƒæ—¶ç›¸åŒ
train_output_dir = './data/cache_imei/a_spec_imei/output_train'
# æŒ‡å®šä¸€ä¸ªä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡çš„æ–‡ä»¶å¤¹ï¼Œæœ¬å‚æ•°å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹
output_dir = './data/cache_imei/a_spec_imei/output_generated'
# ä½¿ç”¨å‡¤å† éœå¸”é£æ ¼æ¨¡å‹ï¼Œé»˜è®¤False
use_style = False
```

ä¹‹åæ‰§è¡Œï¼š

```python
python run_inference.py
```

å³å¯åœ¨`output_dir`ä¸­æ‰¾åˆ°ç”Ÿæˆçš„ä¸ªäººæ•°å­—å½¢è±¡ç…§ç‰‡ã€‚
                                             
# ç®—æ³•ä»‹ç»

## åŸºæœ¬åŸç†

ä¸ªäººå†™çœŸæ¨¡å‹çš„èƒ½åŠ›æ¥æºäºStable Diffusionæ¨¡å‹çš„æ–‡ç”Ÿå›¾åŠŸèƒ½ï¼Œè¾“å…¥ä¸€æ®µæ–‡æœ¬æˆ–ä¸€ç³»åˆ—æç¤ºè¯ï¼Œè¾“å‡ºå¯¹åº”çš„å›¾åƒã€‚æˆ‘ä»¬è€ƒè™‘å½±å“ä¸ªäººå†™çœŸç”Ÿæˆæ•ˆæœçš„ä¸»è¦å› ç´ ï¼šå†™çœŸé£æ ¼ä¿¡æ¯ï¼Œä»¥åŠç”¨æˆ·äººç‰©ä¿¡æ¯ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åˆ†åˆ«ä½¿ç”¨çº¿ä¸‹è®­ç»ƒçš„é£æ ¼LoRAæ¨¡å‹å’Œçº¿ä¸Šè®­ç»ƒçš„äººè„¸LoRAæ¨¡å‹ä»¥å­¦ä¹ ä¸Šè¿°ä¿¡æ¯ã€‚LoRAæ˜¯ä¸€ç§å…·æœ‰è¾ƒå°‘å¯è®­ç»ƒå‚æ•°çš„å¾®è°ƒæ¨¡å‹ï¼Œåœ¨Stable Diffusionä¸­ï¼Œå¯ä»¥é€šè¿‡å¯¹å°‘é‡è¾“å…¥å›¾åƒè¿›è¡Œæ–‡ç”Ÿå›¾è®­ç»ƒçš„æ–¹å¼å°†è¾“å…¥å›¾åƒçš„ä¿¡æ¯æ³¨å…¥åˆ°LoRAæ¨¡å‹ä¸­ã€‚å› æ­¤ï¼Œä¸ªäººå†™çœŸæ¨¡å‹çš„èƒ½åŠ›åˆ†ä¸ºè®­ç»ƒä¸æ¨æ–­ä¸¤ä¸ªé˜¶æ®µï¼Œè®­ç»ƒé˜¶æ®µç”Ÿæˆç”¨äºå¾®è°ƒStable Diffusionæ¨¡å‹çš„å›¾åƒä¸æ–‡æœ¬æ ‡ç­¾æ•°æ®ï¼Œå¾—åˆ°äººè„¸LoRAæ¨¡å‹ï¼›æ¨æ–­é˜¶æ®µåŸºäºäººè„¸LoRAæ¨¡å‹å’Œé£æ ¼LoRAæ¨¡å‹ç”Ÿæˆä¸ªäººå†™çœŸå›¾åƒã€‚  
    
![image](resources/framework.jpg)

## è®­ç»ƒé˜¶æ®µ

è¾“å…¥ï¼šç”¨æˆ·ä¸Šä¼ çš„åŒ…å«æ¸…æ™°äººè„¸åŒºåŸŸçš„å›¾åƒ
                                             
è¾“å‡ºï¼šäººè„¸LoRAæ¨¡å‹
                                             
æè¿°ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬åˆ†åˆ«ä½¿ç”¨åŸºäºæœå‘åˆ¤æ–­çš„å›¾åƒæ—‹è½¬æ¨¡å‹ï¼Œä»¥åŠåŸºäºäººè„¸æ£€æµ‹å’Œå…³é”®ç‚¹æ¨¡å‹çš„äººè„¸ç²¾ç»†åŒ–æ—‹è½¬æ–¹æ³•å¤„ç†ç”¨æˆ·ä¸Šä¼ å›¾åƒï¼Œå¾—åˆ°åŒ…å«æ­£å‘äººè„¸çš„å›¾åƒï¼›æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨äººä½“è§£ææ¨¡å‹å’Œäººåƒç¾è‚¤æ¨¡å‹ï¼Œä»¥è·å¾—é«˜è´¨é‡çš„äººè„¸è®­ç»ƒå›¾åƒï¼›éšåï¼Œæˆ‘ä»¬ä½¿ç”¨äººè„¸å±æ€§æ¨¡å‹å’Œæ–‡æœ¬æ ‡æ³¨æ¨¡å‹ï¼Œç»“åˆæ ‡ç­¾åå¤„ç†æ–¹æ³•ï¼Œäº§ç”Ÿè®­ç»ƒå›¾åƒçš„ç²¾ç»†åŒ–æ ‡ç­¾ï¼›æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸Šè¿°å›¾åƒå’Œæ ‡ç­¾æ•°æ®å¾®è°ƒStable Diffusionæ¨¡å‹å¾—åˆ°äººè„¸LoRAæ¨¡å‹ã€‚

## æ¨æ–­é˜¶æ®µ

è¾“å…¥ï¼šè®­ç»ƒé˜¶æ®µç”¨æˆ·ä¸Šä¼ å›¾åƒï¼Œé¢„è®¾çš„ç”¨äºç”Ÿæˆä¸ªäººå†™çœŸçš„è¾“å…¥æç¤ºè¯
                                             
è¾“å‡ºï¼šä¸ªäººå†™çœŸå›¾åƒ
                                             
æè¿°ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬å°†äººè„¸LoRAæ¨¡å‹å’Œé£æ ¼LoRAæ¨¡å‹çš„æƒé‡èåˆåˆ°Stable Diffusionæ¨¡å‹ä¸­ï¼›æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨Stable Diffusionæ¨¡å‹çš„æ–‡ç”Ÿå›¾åŠŸèƒ½ï¼ŒåŸºäºé¢„è®¾çš„è¾“å…¥æç¤ºè¯åˆæ­¥ç”Ÿæˆä¸ªäººå†™çœŸå›¾åƒï¼›éšåï¼Œæˆ‘ä»¬ä½¿ç”¨äººè„¸èåˆæ¨¡å‹è¿›ä¸€æ­¥æ”¹å–„ä¸Šè¿°å†™çœŸå›¾åƒçš„äººè„¸ç»†èŠ‚ï¼Œå…¶ä¸­ç”¨äºèåˆçš„æ¨¡æ¿äººè„¸é€šè¿‡äººè„¸è´¨é‡è¯„ä¼°æ¨¡å‹åœ¨è®­ç»ƒå›¾åƒä¸­æŒ‘é€‰ï¼›æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨äººè„¸è¯†åˆ«æ¨¡å‹è®¡ç®—ç”Ÿæˆçš„å†™çœŸå›¾åƒä¸æ¨¡æ¿äººè„¸çš„ç›¸ä¼¼åº¦ï¼Œä»¥æ­¤å¯¹å†™çœŸå›¾åƒè¿›è¡Œæ’åºï¼Œå¹¶è¾“å‡ºæ’åé å‰çš„ä¸ªäººå†™çœŸå›¾åƒä½œä¸ºæœ€ç»ˆè¾“å‡ºç»“æœã€‚    

## æ¨¡å‹åˆ—è¡¨

é™„ï¼ˆæµç¨‹å›¾ä¸­æ¨¡å‹é“¾æ¥ï¼‰

[1]  äººè„¸æ£€æµ‹+å…³é”®ç‚¹æ¨¡å‹DamoFDï¼šhttps://modelscope.cn/models/damo/cv_ddsar_face-detection_iclr23-damofd

[2]  å›¾åƒæ—‹è½¬æ¨¡å‹ï¼šåˆ›ç©ºé—´å†…ç½®æ¨¡å‹

[3]  äººä½“è§£ææ¨¡å‹M2FPï¼šhttps://modelscope.cn/models/damo/cv_resnet101_image-multiple-human-parsing

[4]  äººåƒç¾è‚¤æ¨¡å‹ABPNï¼šhttps://www.modelscope.cn/models/damo/cv_unet_skin_retouching_torch

[5]  äººè„¸å±æ€§æ¨¡å‹FairFaceï¼šhttps://modelscope.cn/models/damo/cv_resnet34_face-attribute-recognition_fairface

[6]  æ–‡æœ¬æ ‡æ³¨æ¨¡å‹Deepbooruï¼šhttps://github.com/KichangKim/DeepDanbooru

[7]  æ¨¡æ¿è„¸ç­›é€‰æ¨¡å‹FQAï¼šhttps://modelscope.cn/models/damo/cv_manual_face-quality-assessment_fqa

[8]  äººè„¸èåˆæ¨¡å‹ï¼šhttps://www.modelscope.cn/models/damo/cv_unet_face_fusion_torch

[9]  äººè„¸è¯†åˆ«æ¨¡å‹RTSï¼šhttps://modelscope.cn/models/damo/cv_ir_face-recognition-ood_rts      

[10] äººè„¸è¯´è¯æ¨¡å‹ï¼šhttps://modelscope.cn/models/wwd123/sadtalker

# æ›´å¤šä¿¡æ¯

- [ModelScope library](https://github.com/modelscope/modelscope/)

  ModelScope Libraryæ˜¯ä¸€ä¸ªæ‰˜ç®¡äºgithubä¸Šçš„æ¨¡å‹ç”Ÿæ€ä»“åº“ï¼Œéš¶å±äºè¾¾æ‘©é™¢é­”æ­é¡¹ç›®ã€‚

- [è´¡çŒ®æ¨¡å‹åˆ°ModelScope](https://modelscope.cn/docs/ModelScope%E6%A8%A1%E5%9E%8B%E6%8E%A5%E5%85%A5%E6%B5%81%E7%A8%8B%E6%A6%82%E8%A7%88)

# License

This project is licensed under the [Apache License (Version 2.0)](https://github.com/modelscope/modelscope/blob/master/LICENSE).

